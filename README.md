# Red-Teaming-Challenge-OpenAI-gpt-oss-20b
Fictional Prompts, Real Risks: Testing Model Boundaries. Across five fictional stories, the model revealed unsafe details it should have refused. This red-team challenge shows how harmless prompts can bypass guardrails, leading to blackmail, coercion, or exploit methods. The task is to detect, prevent, and steer outputs to safer ground.


   
   
